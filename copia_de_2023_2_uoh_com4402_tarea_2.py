# -*- coding: utf-8 -*-
"""Copia de 2023_2_UOH_COM4402_Tarea_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pJO0_vRFBJfIJfPU6pDKRN1PWV-zXWoY

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Ingrese su nombre y apellido

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.

## Observación: Antes de ejecutar su código, active el uso de GPU en Google Colab para acelerar el proceso de entrenamiento.

### Para esto: vaya a "Entorno de Ejecución" en el menú superior, haga click en "Cambiar tipo de entorno de ejecución", y seleccionar/verificar "GPU" en "Acelerador de Hardware"
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""## Subir datasets de dígitos (train)"""

!wget raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt
!wget raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt



"""## Leer dataset de dígitos"""

column_names = ["feat" + str(i) for i in range(64)]
column_names.append("class")

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)
df_train_val

df_test = pd.read_csv('1_digits_test.txt', names = column_names)
df_test

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10)

scaler = StandardScaler().fit(df_train.iloc[:,0:64])
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])

df_train

"""## Crear modelo"""

model = nn.Sequential(
          nn.Linear(64, 10),
          nn.ReLU(),
          nn.Linear(10,10)
        )

device = torch.device('cuda')

model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

"""## Crear datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)
labels_train = df_train.to_numpy()[:,64].astype(int)
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:,64].astype(int)
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)
labels_test = df_test.to_numpy()[:,64].astype(int)
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)

"""## Entrenamiento"""

start = time.time()

# loop over the dataset multiple times
for epoch in range(250):
  model.train()
  # Train on the current epoch
  for i, data in enumerate(dataloader_train, 0):
    # Process the current batch
    inputs = data["features"].to(device)
    labels = data["labels"].to(device)
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model(inputs)
    loss = criterion(outputs, labels)
    loss.backward() # backpropagation
    optimizer.step()

    # Por completar: calcule la pérdida de validación y acurracy en el batch actual

    _, predicted = torch.max(outputs, 1)
    correct_train = (predicted == labels).sum().item()
    accuracy_train = correct_train / len(labels)






  model.eval()
  total_val_loss = 0
  correct_val = 0
  total_val = 0
  with torch.no_grad():
    # Por completar: calcule la pérdida de validación y acurracy en la época actual
   for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model(inputs)

            loss_val = criterion(outputs, labels)
            total_val_loss += loss_val.item()

            _, predicted = torch.max(outputs, 1)
            correct_val += (predicted == labels).sum().item()
            total_val += labels.size(0)
  accuracy_val = correct_val / total_val
  average_val_loss = total_val_loss / len(dataloader_val)


  # Por hacer: imprima la pérdida de entrenamiento/validación y acurracy en la época actual
  #print('epoch %d' % (epoch))
  print(f'Epoch {epoch}, Train Loss: {loss.item():.4f}, Train Acc: {accuracy_train:.4f}, Val Loss: {average_val_loss:.4f}, Val Acc: {accuracy_val:.4f}')

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))

from sklearn.metrics import confusion_matrix, accuracy_score

#Primero definimos algunas funciones para graficar y generar las matrices

import matplotlib.pyplot as plt

def plot_loss(train_losses, val_losses):
    plt.plot(train_losses, label='Entrenamiento Loss')
    plt.plot(val_losses, label='Validacion Loss')
    plt.xlabel('Epocas')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()




#Aca definimos la parte c y d , en donde se genera la matriz de confusion normalizada y el accuracy
#Lo hacemos de esta manera para no tener que modificar el codigo tantas veces.

from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns

def compute_confusion_matrix_and_accuracy(model, dataloader):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for data in dataloader:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    cm = confusion_matrix(all_labels, all_preds, normalize='true')
    acc = accuracy_score(all_labels, all_preds)
    return cm, acc
#Aca ploteamos los resultados para obtener una clarificacion de los resultados obtenidos
def plot_confusion_matrix(cm):
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, cmap='Blues')
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
    plt.show()

#PARTE A

#Definimos algunas listas para ir guardando los resultados, esto nos servira mientras avanzamos en la tarea y tambien para la parte 3
lista_accuracies = []
train_accuracies_a = []
train_losses_a = []
val_losses_a = []
val_accuracies_a = []
# aca definimos la red neuronal
class NeuralNetA(nn.Module):
    def __init__(self):
        super(NeuralNetA, self).__init__()
        self.layer1 = nn.Linear(64, 10)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(10, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        return x
#Creamos modelo
model_a = NeuralNetA().to(device)

#implementamos que se detenga el entrenamiento cuando el loss de validacion comience a aumentar mientras que el de entrenamiento siga bajando.

optimizer = torch.optim.Adam(model_a.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

num_epochs = 1000
patience = 20  # Número de épocas para esperar antes de detener el entrenamiento
best_val_loss = float('inf')
epochs_no_improve = 0

start = time.time()

for epoch in range(num_epochs):
    # Aca el Entrenamiento
    model_a.train()
    running_train_loss = 0.0
    correct_train_preds = 0
    total_train_samples = 0
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_a(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)
        running_train_loss += loss.item()
        correct_train_preds += (preds == labels).sum().item()
        total_train_samples += labels.size(0)
        loss.backward()
        optimizer.step()

    average_train_loss = running_train_loss / len(dataloader_train)
    train_accuracy = correct_train_preds / total_train_samples
    train_losses_a.append(average_train_loss)
    train_accuracies_a.append(train_accuracy)









    # Creamos la parte de validación
    model_a.eval()
    val_loss = 0.0
    correct_val_preds = 0
    total_val_samples = 0
    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_a(inputs)
            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item()
            _, preds = torch.max(outputs, 1)
            correct_val_preds += (preds == labels).sum().item()
            total_val_samples += labels.size(0)

    average_val_loss = val_loss / len(dataloader_val)
    val_accuracy = correct_val_preds / total_val_samples

    # Guardamos los resultados
    train_losses_a.append(average_train_loss)
    train_accuracies_a.append(train_accuracy)
    val_losses_a.append(average_val_loss)
    val_accuracies_a.append(val_accuracy)



    # Calculamos el accuracy de validación para esta época
    _, acc_val_current = compute_confusion_matrix_and_accuracy(model_a, dataloader_val)
    lista_accuracies.append(acc_val_current)


    # Verificamos si el loss de validación ha mejorado
    if average_val_loss < best_val_loss:
        best_val_loss = average_val_loss
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1




    # Si el loss de validación no mejora durante 'patience' epocas, detener el entrenamiento
    if epochs_no_improve == patience:
        print(f"Early stopping en epoca {epoch}")
        break

    print(f'Epoch {epoch}, Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {acc_val_current:.4f}')
    train_losses_a.append(loss.item())
    val_losses_a.append(average_val_loss)

end = time.time()

print('Entrenamiento finalizado, total tiempo %f seconds' % (end - start))#Printeamos el tiempo
# Cálculo del accuracy de validación para model_a
_, acc_val_a = compute_confusion_matrix_and_accuracy(model_a, dataloader_val)
print(f"Validation Accuracy for model_a: {acc_val_a:.4f}")

# (b) Graficamos el loss de entrenamiento y validación
plot_loss(train_losses_a, val_losses_a)

# (c) Generamos la matriz de confusión y accuracy para el conjunto de entrenamiento
cm_train, acc_train = compute_confusion_matrix_and_accuracy(model_a, dataloader_train)
print(f"Training Accuracy: {acc_train:.4f}")
plot_confusion_matrix(cm_train)

# (d) Generamos la matriz de confusión y accuracy para el conjunto de validación
cm_val, acc_val = compute_confusion_matrix_and_accuracy(model_a, dataloader_val)
print(f"Validation Accuracy: {acc_val:.4f}")
plot_confusion_matrix(cm_val)

# B)
#Basicamente repetimos todos los pasos anteriores, para no tener que comentar todo , en pocas palabras solo se modifican las caracteristicas en cada modelo.
train_losses_b = []
train_accuracies_b = []
val_losses_b = []
val_accuracies_b = []

#definimos la red neuronal

class NeuralNetB(nn.Module):
    def __init__(self):
        super(NeuralNetB, self).__init__()
        self.layer1 = nn.Linear(64, 40)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(40, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        return x

model_b = NeuralNetB().to(device)


# entrenamos la red

optimizer = torch.optim.Adam(model_b.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

best_val_loss = float('inf')
epochs_no_improve = 0

start = time.time()

for epoch in range(num_epochs):

    train_loss = 0.0
    correct_train_preds = 0
    total_train_samples = 0


    # Entrenamiento
    model_b.train()
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_b(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        correct_train_preds += (preds == labels).sum().item()
        total_train_samples += labels.size(0)

    average_train_loss = train_loss / len(dataloader_train)
    train_accuracy = correct_train_preds / total_train_samples


    # Validación
    model_b.eval()
    val_loss = 0.0
    correct_val_preds = 0
    total_val_samples = 0
    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_b(inputs)
            _, preds = torch.max(outputs, 1)
            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item()
            correct_val_preds += (preds == labels).sum().item()
            total_val_samples += labels.size(0)

    average_val_loss = val_loss / len(dataloader_val)
    val_accuracy = correct_val_preds / total_val_samples


   # Guardamos los resultados
    train_losses_b.append(average_train_loss)
    train_accuracies_b.append(train_accuracy)
    val_losses_b.append(average_val_loss)
    val_accuracies_b.append(val_accuracy)




    # Verificamos si el loss de validación ha mejorado


    if average_val_loss < best_val_loss:
        best_val_loss = average_val_loss
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    # Si el loss de validación no mejora durante 'patience' epocas, detener el entrenamiento
    if epochs_no_improve == patience:
        print(f"Early stopping at epoch {epoch}")
        break

    print(f'Epoch {epoch}, Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')



end = time.time()
print('Entrenamiento finalizado, total tiempo %f seconds' % (end - start))

# Cálculo del accuracy de validación para model_b
_, acc_val_b = compute_confusion_matrix_and_accuracy(model_b, dataloader_val)
print(f"Validation Accuracy for model_a: {acc_val_b:.4f}")

# (b) Graficamos el loss de entrenamiento y validación
plot_loss(train_losses_b, val_losses_b)

# (c) Generamos la matriz de confusión y accuracy para el conjunto de entrenamiento
cm_train, acc_train = compute_confusion_matrix_and_accuracy(model_b, dataloader_train)
print(f"Training Accuracy: {acc_train:.4f}")
plot_confusion_matrix(cm_train)

# (d) Generamos la matriz de confusión y accuracy para el conjunto de validación
cm_val, acc_val = compute_confusion_matrix_and_accuracy(model_b, dataloader_val)
print(f"Validation Accuracy: {acc_val:.4f}")
plot_confusion_matrix(cm_val)

#PARTE C


train_losses_c = []
train_accuracies_c = []
val_losses_c = []
val_accuracies_c = []

# Definimos la red neuronal para el caso (c)
class NeuralNetC(nn.Module):
    def __init__(self):
        super(NeuralNetC, self).__init__()
        self.layer1 = nn.Linear(64, 10)
        self.tanh = nn.Tanh()
        self.layer2 = nn.Linear(10, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = self.tanh(x)
        x = self.layer2(x)
        return x

model_c = NeuralNetC().to(device)

# Entrenamos la red
optimizer = torch.optim.Adam(model_c.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

best_val_loss = float('inf')
epochs_no_improve = 0

start = time.time()

for epoch in range(num_epochs):

    train_loss = 0.0
    correct_train_preds = 0
    total_train_samples = 0
    # Entrenamiento
    model_c.train()
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_c(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        correct_train_preds += (preds == labels).sum().item()
        total_train_samples += labels.size(0)

    average_train_loss = train_loss / len(dataloader_train)
    train_accuracy = correct_train_preds / total_train_samples




    # Validación
    model_c.eval()
    val_loss = 0.0
    correct_val_preds = 0
    total_val_samples = 0
    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_c(inputs)
            _, preds = torch.max(outputs, 1)
            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item()
            correct_val_preds += (preds == labels).sum().item()
            total_val_samples += labels.size(0)

    average_val_loss = val_loss / len(dataloader_val)
    val_accuracy = correct_val_preds / total_val_samples

    # Guardamos los resultados
    train_losses_c.append(average_train_loss)
    train_accuracies_c.append(train_accuracy)
    val_losses_c.append(average_val_loss)
    val_accuracies_c.append(val_accuracy)






    # Verificar si el loss de validación ha mejorado
    if average_val_loss < best_val_loss:
        best_val_loss = average_val_loss
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    # Si el loss de validación no mejora durante 'patience' épocas, detener el entrenamiento
    if epochs_no_improve == patience:
        print(f"Early stopping at epoch {epoch}")
        break

    print(f'Epoch {epoch}, Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')

end = time.time()
print('Entrenamiento finalizado, total tiempo %f seconds' % (end - start))

# (b) Graficar el loss de entrenamiento y validación
plot_loss(train_losses_c, val_losses_c)

# (c) Generar la matriz de confusión y accuracy para el conjunto de entrenamiento
cm_train, acc_train = compute_confusion_matrix_and_accuracy(model_c, dataloader_train)
print(f"Training Accuracy: {acc_train:.4f}")
plot_confusion_matrix(cm_train)

# (d) Generar la matriz de confusión y accuracy para el conjunto de validación
cm_val, acc_val = compute_confusion_matrix_and_accuracy(model_c, dataloader_val)
print(f"Validation Accuracy: {acc_val:.4f}")
plot_confusion_matrix(cm_val)

# D)

train_losses_d = []
train_accuracies_d = []
val_losses_d = []
val_accuracies_d = []

# Definimos la red neuronal para el caso (d)
class NeuralNetD(nn.Module):
    def __init__(self):
        super(NeuralNetD, self).__init__()
        self.layer1 = nn.Linear(64, 40)
        self.tanh = nn.Tanh()
        self.layer2 = nn.Linear(40, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = self.tanh(x)
        x = self.layer2(x)
        return x

model_d = NeuralNetD().to(device)

# Entrenamos la red
optimizer = torch.optim.Adam(model_d.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

best_val_loss = float('inf')
epochs_no_improve = 0

start = time.time()

for epoch in range(num_epochs):

    train_loss = 0.0
    correct_train_preds = 0
    total_train_samples = 0
    # Entrenamiento
    model_d.train()
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_d(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        correct_train_preds += (preds == labels).sum().item()
        total_train_samples += labels.size(0)

    average_train_loss = train_loss / len(dataloader_train)
    train_accuracy = correct_train_preds / total_train_samples

    # Validación
    model_d.eval()
    val_loss = 0.0
    correct_val_preds = 0
    total_val_samples = 0
    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_d(inputs)
            _, preds = torch.max(outputs, 1)
            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item()
            correct_val_preds += (preds == labels).sum().item()
            total_val_samples += labels.size(0)

    average_val_loss = val_loss / len(dataloader_val)
    val_accuracy = correct_val_preds / total_val_samples

    # Guardamos los resultados
    train_losses_d.append(average_train_loss)
    train_accuracies_d.append(train_accuracy)
    val_losses_d.append(average_val_loss)
    val_accuracies_d.append(val_accuracy)

    # Verificar si el loss de validación ha mejorado
    if average_val_loss < best_val_loss:
        best_val_loss = average_val_loss
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    # Si el loss de validación no mejora durante 'patience' épocas, detener el entrenamiento
    if epochs_no_improve == patience:
        print(f"Early stopping at epoch {epoch}")
        break

    print(f'Epoch {epoch}, Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')

end = time.time()
print('Finished Training, total time %f seconds' % (end - start))

# (b) Graficamos el loss de entrenamiento y validación
plot_loss(train_losses_d, val_losses_d)

# (c) Generamos la matriz de confusión y accuracy para el conjunto de entrenamiento
cm_train, acc_train = compute_confusion_matrix_and_accuracy(model_d, dataloader_train)
print(f"Training Accuracy: {acc_train:.4f}")
plot_confusion_matrix(cm_train)

# (d) Generamos la matriz de confusión y accuracy para el conjunto de validación
cm_val, acc_val = compute_confusion_matrix_and_accuracy(model_d, dataloader_val)
print(f"Validation Accuracy: {acc_val:.4f}")
plot_confusion_matrix(cm_val)

# E)

train_losses_e = []
train_accuracies_e = []
val_losses_e = []
val_accuracies_e = []


# Definimos la red neuronal para el caso (e)
class NeuralNetE(nn.Module):
    def __init__(self):
        super(NeuralNetE, self).__init__()
        self.layer1 = nn.Linear(64, 10)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(10, 10)
        self.layer3 = nn.Linear(10, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        x = self.relu(x)
        x = self.layer3(x)
        return x

model_e = NeuralNetE().to(device)

# Entrenamos la red
optimizer = torch.optim.Adam(model_e.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

best_val_loss = float('inf')
epochs_no_improve = 0

start = time.time()

for epoch in range(num_epochs):

    train_loss = 0.0
    correct_train_preds = 0
    total_train_samples = 0
    # Entrenamiento
    model_e.train()
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_e(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        correct_train_preds += (preds == labels).sum().item()
        total_train_samples += labels.size(0)

    average_train_loss = train_loss / len(dataloader_train)
    train_accuracy = correct_train_preds / total_train_samples

    # Validación
    model_e.eval()
    val_loss = 0.0
    correct_val_preds = 0
    total_val_samples = 0
    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_e(inputs)
            _, preds = torch.max(outputs, 1)
            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item()
            correct_val_preds += (preds == labels).sum().item()
            total_val_samples += labels.size(0)

    average_val_loss = val_loss / len(dataloader_val)
    val_accuracy = correct_val_preds / total_val_samples

    # Guardamos los resultados
    train_losses_e.append(average_train_loss)
    train_accuracies_e.append(train_accuracy)
    val_losses_e.append(average_val_loss)
    val_accuracies_e.append(val_accuracy)

    # Verificar si el loss de validación ha mejorado
    if average_val_loss < best_val_loss:
        best_val_loss = average_val_loss
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    # Si el loss de validación no mejora durante 'patience' épocas, detener el entrenamiento
    if epochs_no_improve == patience:
        print(f"Early stopping at epoch {epoch}")
        break

    print(f'Epoch {epoch}, Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')

end = time.time()
print('Entrenamiento finalizado, total tiempo %f seconds' % (end - start))

# Graficamos el loss de entrenamiento y validación
plot_loss(train_losses_e, val_losses_e)

# Generamos la matriz de confusión y accuracy para el conjunto de entrenamiento
cm_train, acc_train = compute_confusion_matrix_and_accuracy(model_e, dataloader_train)
print(f"Training Accuracy: {acc_train:.4f}")
plot_confusion_matrix(cm_train)

# Generamos la matriz de confusión y accuracy para el conjunto de validación
cm_val, acc_val = compute_confusion_matrix_and_accuracy(model_e, dataloader_val)
print(f"Validation Accuracy: {acc_val:.4f}")
plot_confusion_matrix(cm_val)

# F)

train_losses_f = []
train_accuracies_f = []
val_losses_f = []
val_accuracies_f = []

# Definimos la red neuronal para el caso (f)
class NeuralNetF(nn.Module):
    def __init__(self):
        super(NeuralNetF, self).__init__()
        self.layer1 = nn.Linear(64, 40)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(40, 40)
        self.layer3 = nn.Linear(40, 10)

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        x = self.relu(x)
        x = self.layer3(x)
        return x

model_f = NeuralNetF().to(device)

# Entrenamos la red
optimizer = torch.optim.Adam(model_f.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

best_val_loss = float('inf')
epochs_no_improve = 0

start = time.time()

for epoch in range(num_epochs):

    train_loss = 0.0
    correct_train_preds = 0
    total_train_samples = 0
    # Entrenamiento
    model_f.train()
    for data in dataloader_train:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        optimizer.zero_grad()
        outputs = model_f(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        correct_train_preds += (preds == labels).sum().item()
        total_train_samples += labels.size(0)

    average_train_loss = train_loss / len(dataloader_train)
    train_accuracy = correct_train_preds / total_train_samples

    # Validación
    model_f.eval()
    val_loss = 0.0
    correct_val_preds = 0
    total_val_samples = 0
    with torch.no_grad():
        for data in dataloader_val:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model_f(inputs)
            _, preds = torch.max(outputs, 1)
            loss_val = criterion(outputs, labels)
            val_loss += loss_val.item()
            correct_val_preds += (preds == labels).sum().item()
            total_val_samples += labels.size(0)

    average_val_loss = val_loss / len(dataloader_val)
    val_accuracy = correct_val_preds / total_val_samples

    # Guardamos los resultados
    train_losses_f.append(average_train_loss)
    train_accuracies_f.append(train_accuracy)
    val_losses_f.append(average_val_loss)
    val_accuracies_f.append(val_accuracy)

    # Verificar si el loss de validación ha mejorado
    if average_val_loss < best_val_loss:
        best_val_loss = average_val_loss
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1

    # Si el loss de validación no mejora durante 'patience' épocas, detener el entrenamiento
    if epochs_no_improve == patience:
        print(f"Early stopping at epoch {epoch}")
        break

    print(f'Epoch {epoch}, Train Loss: {average_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')

end = time.time()
print('Entrenamiento finalizado, total tiempo %f seconds' % (end - start))

# Graficamos el loss de entrenamiento y validación
plot_loss(train_losses_f, val_losses_f)

# Generamos la matriz de confusión y accuracy para el conjunto de entrenamiento
cm_train, acc_train = compute_confusion_matrix_and_accuracy(model_f, dataloader_train)
print(f"Training Accuracy: {acc_train:.4f}")
plot_confusion_matrix(cm_train)

# Generamos la matriz de confusión y accuracy para el conjunto de validación
cm_val, acc_val = compute_confusion_matrix_and_accuracy(model_f, dataloader_val)
print(f"Validation Accuracy: {acc_val:.4f}")
plot_confusion_matrix(cm_val)

#PARTE 3



final_accuracy_a = val_accuracies_a[-1]
final_accuracy_b = val_accuracies_b[-1]
final_accuracy_c = val_accuracies_c[-1]
final_accuracy_d = val_accuracies_d[-1]
final_accuracy_e = val_accuracies_e[-1]
final_accuracy_f = val_accuracies_f[-1]

# Encuentra el modelo con la mayor accuracy al final del entrenamiento
best_model_accuracy = max(final_accuracy_a, final_accuracy_b, final_accuracy_c,
                          final_accuracy_d, final_accuracy_e, final_accuracy_f)

best_model = None

if best_model_accuracy == final_accuracy_a:
    best_model = model_a
    print("El mejor modelo es (a)")
elif best_model_accuracy == final_accuracy_b:
    best_model = model_b
    print("El mejor modelo es (b)")
elif best_model_accuracy == final_accuracy_c:
    best_model = model_c
    print("El mejor modelo es (c)")
elif best_model_accuracy == final_accuracy_d:
    best_model = model_d
    print("El mejor modelo es (d)")
elif best_model_accuracy == final_accuracy_e:
    best_model = model_e
    print("El mejor modelo es (e)")
else:
    best_model = model_f
    print("El mejor modelo es (f)")

print(f"Con una accuracy de validación de: {best_model_accuracy:.4f}")

# Asegurarnos de que el modelo esté en modo de evaluación y en el dispositivo correcto
model_b = model_b.eval().to(device)

# Inicializamos las variables necesarias para el cálculo
correct_preds = 0
total_samples = 0
cm_array = np.zeros((10, 10))  # Cambiado el nombre aquí

# Evaluamos el modelo en el conjunto de prueba
with torch.no_grad():
    for data in dataloader_test:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = model_b(inputs)
        _, preds = torch.max(outputs, 1)

        # Actualizamos la matriz de confusión
        for t, p in zip(labels.view(-1), preds.view(-1)):
            cm_array[t.long(), p.long()] += 1  # Y aquí igual

        correct_preds += (preds == labels).sum().item()
        total_samples += labels.size(0)

# Generamos la matriz de confusión y accuracy para el conjunto de prueba
cm_test, acc_test = compute_confusion_matrix_and_accuracy(model_b, dataloader_test)
print(f"Test Accuracy: {acc_test:.4f}")
plot_confusion_matrix(cm_test)